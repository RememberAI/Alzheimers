import React, { useRef, useEffect, useState, useCallback } from 'react';
import Head from 'next/head';
import { Box, Paper, ThemeProvider, createTheme, CssBaseline } from '@mui/material';
import { grey } from '@mui/material/colors';

// --- Material-UI Theme ---
const theme = createTheme({
  palette: { mode: 'light', background: { default: '#f8f8f8', paper: '#ffffff', }, text: { primary: grey[900], secondary: grey[700], }, error: { main: '#d32f2f', }, },
  components: { MuiPaper: { styleOverrides: { root: { borderRadius: '16px', boxShadow: '0 4px 12px rgba(0,0,0,0.08)', border: `1px solid ${grey[200]}`, position: 'relative', overflow: 'hidden', } } } },
});

// --- p5.js Sketch Definition ---
const sketch = (p) => {
  // --- Audio Analysis Setup ---
  let audioContext; let analyser; let microphone; let micStream; let frequencyData;
  let audioReady = false; let sampleRate = 44100;
  const audioThreshold = 0.09;
  const fftSize = 512;
  let nyquist;

  // --- State Management (within p5) ---
  let isP5StateActive = false;
  let activeStateIntensity = 0; const activeStateLerpFactor = 0.07;

  // --- Blob Geometry & Core Properties ---
  let baseRadius = 100;
  const numVertices = 140; let vertices = [];

  // --- Core "Breathing" & Pause Effects ---
  let breathingTime = Math.random() * 500;
  const breathingSpeed = 0.0008; const breathingAmount = 0.025;
  let isBreathing = false; let silenceFrames = 0;
  const silenceThreshold = 0.03; const framesForBreathing = 90;
  const framesForPause = 20;
  let pauseEnded = false;
  let pauseEffectTimer = 0; const pauseEffectDuration = 12;
  let pauseEffectIntensity = 0; const pauseEffectDecay = 0.06;
  let inhaleAmount = 0;
  const inhaleSpeed = 0.15;
  const maxInhaleFactor = 0.08;

  // --- Noise Parameters ---
  // Passive
  let passiveNoiseTime = Math.random() * 1000; const basePassiveNoiseSpeed = 0.0010;
  const passiveNoisePosScale = 0.7;
  let currentPassiveDeformationAmount = 0.25;
  const basePassiveDeformationAmount = 0.25;
  const maxPassiveDeformationBoost = 0.12;
  const passiveDeformationLerpFactor = 0.015;
  // Active - Shape
  let activeShapeNoiseTime = Math.random() * 2000; const baseActiveShapeNoiseSpeed = 0.0015;
  const baseActiveShapeNoiseScale = 1.8;
  let currentActiveShapeNoiseScale = baseActiveShapeNoiseScale;
  const shapeScaleLerpFactor = 0.015;
  const shapeScaleSpreadFactor = 0.5;
  // Active - Texture
  let activeTextureNoiseTime = Math.random() * 3000; const baseActiveTextureNoiseSpeed = 0.0025;
  const activeTextureNoiseScale = 9.0; let currentActiveTextureIntensity = 0.10;
  const baseTextureIntensity = 0.05; const maxTextureIntensity = 0.25;
  const textureIntensityLerpFactor = 0.02;
  // Active - Waviness
  let activeWavinessNoiseTime = Math.random() * 4000; const baseActiveWavinessNoiseSpeed = 0.0009;
  let currentWavinessNoiseScale = 4.5;
  const baseWavinessNoiseScale = 4.5;
  const wavinessScalePitchFactor = 1.8;
  const wavinessScaleLerpFactor = 0.02;
  let currentWavinessInfluence = 0.0;
  const maxWavinessInfluence = 0.85;
  const wavinessInfluenceLerpFactor = 0.025;
  // Active - Angular Offset
  let activeNoiseAngularOffset = Math.random() * p.TWO_PI;
  const baseActiveNoiseOffsetSpeed = 0.0003;

  // --- Speed Modulation by Volume ---
  const maxSlowSpeedMultiplier = 3.5;
  const maxFastSpeedMultiplier = 2.2;

  // Peak extension control
  let activePeakMultiplier = 1.0; const activeMultiplierLerpFactor = 0.15;
  const maxPeakExtensionFactor = 1.5;

  // --- Internal Complexity Texture ---
  let internalTextureTime = Math.random() * 6000; const internalTextureSpeed = 0.0003;
  const internalTextureScale = 0.5; const internalTextureComplexityScale = 2.5;
  let internalTextureAlpha = 0; const maxInternalTextureAlpha = 18;
  const internalAlphaLerpFactor = 0.015;

  // --- Edge Sharpness / Certainty Proxy ---
  let edgeSharpness = 1.0; const edgeSharpnessLerpFactor = 0.015;

  // --- Inferred Speech Mode Factors ---
  let focusFactor = 0.0; const focusFactorLerp = 0.02;
  let melodyFactor = 0.0; const melodyFactorLerp = 0.025;
  let emphasisFactor = 0.0; const emphasisFactorLerp = 0.05;

  // --- Audio Reactivity Parameters ---
  let smoothedOverallLevel = 0; let smoothedMidLevel = 0; let smoothedTrebleLevel = 0;
  const audioLerpFactor = 0.1;
  let frequencySpread = 0; const freqSpreadLerpFactor = 0.03;
  const binActivationThreshold = 10;
  let pitchProxy = 0.5; const pitchProxyLerpFactor = 0.06;
  let lastPitchProxy = 0.5;
  let pitchChangeRate = 0; const pitchChangeLerpFactor = 0.05;
  const pitchMinFreq = 80; const pitchMaxFreq = 500;
  let pitchMinIndex, pitchMaxIndex;
  let midHistory = []; const midHistoryLength = 30;
  let sustainedMidLevel = 0;

  // --- Volume Dynamics (Aha! detection) ---
  let volumeHistory = []; const volumeHistoryLength = 60;
  let averageVolume = 0; const ahaThresholdMultiplier = 1.4;
  const ahaMinimumLevel = 0.30; let isAhaMoment = false;
  let ahaTimer = 0; const ahaDuration = 15;

  // --- Color Properties ---
  const baseHue = 208; let hueShiftRange = 35;
  let targetHue = baseHue; let currentHue = baseHue; const hueLerpFactor = 0.02;
  const baseSaturation = 70; const baseBrightness = 96;
  let saturationBoost = 0; const maxSaturationBoost = 25;
  let brightnessBoost = 0; const maxBrightnessBoost = 4;
  let currentCenterColor; let currentEdgeColor; // Assigned in updateColor
  let flashIntensity = 0; const flashDecay = 0.15;

  // --- p5.js Setup ---
  p.setup = () => {
    const container = document.getElementById('canvas-container'); if (!container) return;
    p.createCanvas(container.offsetWidth, container.offsetHeight).parent('canvas-container');
    p.colorMode(p.HSB, 360, 100, 100, 100); p.angleMode(p.RADIANS); p.frameRate(60);
    baseRadius = p.min(p.width, p.height) / 5.0;
    nyquist = sampleRate / 2;
    const binWidth = nyquist / (fftSize / 2);
    pitchMinIndex = Math.max(1, Math.floor(pitchMinFreq / binWidth));
    pitchMaxIndex = Math.min(fftSize / 2 - 1, Math.ceil(pitchMaxFreq / binWidth));
    for (let i = 0; i < numVertices; i++) { vertices.push(p.createVector(0, 0)); }
    for(let i=0; i<volumeHistoryLength; i++) volumeHistory.push(0);
    for(let i=0; i<midHistoryLength; i++) midHistory.push(0);
    currentActiveShapeNoiseScale = baseActiveShapeNoiseScale;
    currentPassiveDeformationAmount = basePassiveDeformationAmount;
    currentWavinessNoiseScale = baseWavinessNoiseScale;
    updateColor(); calculateBlobShape(); drawInternalTexture();
    console.log(`p5 Setup Complete. BaseRadius: ${baseRadius}, Pitch Range Indices: ${pitchMinIndex}-${pitchMaxIndex}`);
  };

  // --- p5.js Draw Loop ---
  p.draw = () => {
    let timeDelta = p.deltaTime / (1000 / 60);
    p.background(p.color(theme.palette.background.default));
    p.translate(p.width / 2, p.height / 2);
    updateAudio();
    updateStateAndMotion(timeDelta);
    updateColor();
    calculateBlobShape();
    drawInternalTexture();
    drawBlob();
    drawMicrophoneIcon();
    if(pauseEffectTimer > 0) drawPauseEffect();
  };
  
  // --- Draw Microphone Icon ---
  const drawMicrophoneIcon = () => {
    const bgColor = p.color(theme.palette.background.default);
    const baseMicSize = baseRadius * 0.2;
    const currentMicSize = baseMicSize * (1 + smoothedOverallLevel * 0.5);
    
    // Draw scaling circle around microphone
    const minCircleRadius = baseMicSize * 1.5;
    const maxCircleRadius = baseRadius * 0.85;
    const circleRadius = p.lerp(minCircleRadius, maxCircleRadius, smoothedOverallLevel);
    p.push();
    p.noFill();
    p.stroke(220, 220, 220);
    p.strokeWeight(1.5);
    p.circle(0, 0, circleRadius * 2);
    p.pop();
    
    // Draw microphone
    p.push();
    p.fill(bgColor);
    p.noStroke();
    
    // Mic capsule
    p.rect(0, -currentMicSize * 0.7, currentMicSize * 0.6, currentMicSize * 1.2, currentMicSize * 0.3);
    
    // Mic stand
    p.rect(0, currentMicSize * 0.5, currentMicSize * 0.15, currentMicSize * 0.5);
    
    // Mic base
    p.ellipse(0, currentMicSize * 1, currentMicSize * 0.6, currentMicSize * 0.2);
    
    p.pop();
  };

  // --- Audio Setup Function ---
  const setupAudio = async () => { if (audioContext && audioContext.state === 'running') { if (!micStream || !micStream.active) { try { micStream = await navigator.mediaDevices.getUserMedia({ audio: { echoCancellation: true, noiseSuppression: true } }); if (microphone) microphone.disconnect(); microphone = audioContext.createMediaStreamSource(micStream); microphone.connect(analyser); console.log("Reconnected mic stream."); } catch (err) { console.error("Error reconnecting mic:", err); audioReady = false; isP5StateActive = false; return false; } } audioReady = true; console.log("Audio already running or reconnected."); return true; } if (audioContext && audioContext.state !== 'closed') { console.log("Closing existing audio context before creating new one."); await audioContext.close().catch(e => console.error("Error closing previous context:", e)); audioContext = null; } try { audioContext = new (window.AudioContext || window.webkitAudioContext)(); sampleRate = audioContext.sampleRate; nyquist = sampleRate / 2; const binWidth = nyquist / (fftSize / 2); pitchMinIndex = Math.max(1, Math.floor(pitchMinFreq / binWidth)); pitchMaxIndex = Math.min(fftSize / 2 - 1, Math.ceil(pitchMaxFreq / binWidth)); if (audioContext.state === 'suspended') { await audioContext.resume(); } micStream = await navigator.mediaDevices.getUserMedia({ audio: { echoCancellation: true, noiseSuppression: true } }); microphone = audioContext.createMediaStreamSource(micStream); analyser = audioContext.createAnalyser(); analyser.fftSize = fftSize; analyser.smoothingTimeConstant = 0.75; frequencyData = new Uint8Array(analyser.frequencyBinCount); microphone.connect(analyser); console.log('Audio setup successful. Context state:', audioContext.state); audioReady = true; return true; } catch (err) { console.error('Audio Setup Error:', err); audioReady = false; isP5StateActive = false; if (micStream) micStream.getTracks().forEach(track => track.stop()); micStream = null; microphone = null; analyser = null; frequencyData = null; if (audioContext && audioContext.state !== 'closed') { await audioContext.close().catch(e => console.error("Error closing context on failure:", e)); } audioContext = null; return false; } };

  // --- Stop Audio Processing ---
  const stopAudioProcessing = () => { console.log("Stopping audio processing and mic tracks."); if (micStream) { micStream.getTracks().forEach(track => track.stop()); micStream = null; } if (microphone) { microphone.disconnect(); microphone = null; } audioReady = false; const stopLerpFactor = audioLerpFactor * 4; smoothedOverallLevel=p.lerp(smoothedOverallLevel,0,stopLerpFactor); smoothedMidLevel=p.lerp(smoothedMidLevel,0,stopLerpFactor); smoothedTrebleLevel=p.lerp(smoothedTrebleLevel,0,stopLerpFactor); frequencySpread = p.lerp(frequencySpread, 0, stopLerpFactor); averageVolume = 0; volumeHistory = volumeHistory.map(() => 0); midHistory = midHistory.map(() => 0); sustainedMidLevel = 0; pitchProxy = 0.5; lastPitchProxy = 0.5; pitchChangeRate = 0; focusFactor=0; melodyFactor=0; emphasisFactor=0; /* Reset mode factors */};

  // --- Update Audio Analysis ---
  const updateAudio = () => { lastPitchProxy = pitchProxy; if (!isP5StateActive || !audioReady || !analyser || !frequencyData) { const idleLerpFactor = audioLerpFactor * 0.3; smoothedOverallLevel=p.lerp(smoothedOverallLevel,0,idleLerpFactor); smoothedMidLevel=p.lerp(smoothedMidLevel,0,idleLerpFactor); smoothedTrebleLevel=p.lerp(smoothedTrebleLevel,0,idleLerpFactor); frequencySpread = p.lerp(frequencySpread, 0, freqSpreadLerpFactor); volumeHistory.push(0); if(volumeHistory.length > volumeHistoryLength) volumeHistory.shift(); averageVolume = volumeHistory.reduce((a, b) => a + b, 0) / volumeHistory.length; midHistory.push(0); if(midHistory.length > midHistoryLength) midHistory.shift(); sustainedMidLevel = midHistory.reduce((a,b) => a+b, 0) / midHistory.length; pitchProxy = p.lerp(pitchProxy, 0.5, pitchProxyLerpFactor); pitchChangeRate = p.lerp(pitchChangeRate, 0, pitchChangeLerpFactor); return; } analyser.getByteFrequencyData(frequencyData); let oSum=0, mSum=0, tSum=0, activeBinCount = 0; const fbc=frequencyData.length; const midEndFreq=4000, trebleStartFreq=4000; const midEndIndex=Math.min(fbc-1,Math.ceil(midEndFreq/(nyquist/fbc))); const trebleStartIndex=Math.min(fbc-1,Math.floor(trebleStartFreq/(nyquist/fbc))); let maxAmp = 0; let peakIndex = -1; for (let i = pitchMinIndex; i <= pitchMaxIndex; i++) { if (frequencyData[i] > maxAmp) { maxAmp = frequencyData[i]; peakIndex = i; } } let targetPitchProxy = 0.5; if (peakIndex !== -1 && maxAmp > binActivationThreshold * 1.5) { targetPitchProxy = p.map(peakIndex, pitchMinIndex, pitchMaxIndex, 0, 1, true); } pitchProxy = p.lerp(pitchProxy, targetPitchProxy, pitchProxyLerpFactor); for(let i=0;i<fbc;i++){ let l=frequencyData[i]; oSum+=l; if(i<=midEndIndex) mSum+=l; else if(i>=trebleStartIndex) tSum+=l; if(l > binActivationThreshold) activeBinCount++; } let nO=fbc>0?oSum/fbc:0; let numMidBins = midEndIndex + 1; let numTrebleBins = fbc - trebleStartIndex; let nM=numMidBins>0?mSum/numMidBins:0; let nT=numTrebleBins>0?tSum/numTrebleBins:0; let normO=p.map(nO,0,160,0,1,true); let normM=p.map(nM,0,160,0,1,true); let normT=p.map(nT,0,160,0,1,true); smoothedOverallLevel = p.lerp(smoothedOverallLevel,normO,audioLerpFactor); smoothedMidLevel = p.lerp(smoothedMidLevel,normM,audioLerpFactor); smoothedTrebleLevel = p.lerp(smoothedTrebleLevel,normT,audioLerpFactor); let targetSpread = fbc > 0 ? activeBinCount / fbc : 0; frequencySpread = p.lerp(frequencySpread, targetSpread, freqSpreadLerpFactor); volumeHistory.push(smoothedOverallLevel); if(volumeHistory.length > volumeHistoryLength) volumeHistory.shift(); averageVolume = volumeHistory.reduce((a, b) => a + b, 0) / volumeHistory.length; midHistory.push(smoothedMidLevel); if(midHistory.length > midHistoryLength) midHistory.shift(); sustainedMidLevel = midHistory.reduce((a,b) => a+b, 0) / midHistory.length; let currentPitchChange = Math.abs(pitchProxy - lastPitchProxy); pitchChangeRate = p.lerp(pitchChangeRate, currentPitchChange, pitchChangeLerpFactor); if (!isAhaMoment && smoothedOverallLevel > ahaMinimumLevel && averageVolume > 0.01 && smoothedOverallLevel > averageVolume * ahaThresholdMultiplier) { isAhaMoment = true; ahaTimer = ahaDuration; flashIntensity = 1.0; console.log("Aha! Detected"); } };

  // --- Update State & Motion ---
  const updateStateAndMotion = (timeDelta) => {
    let targetActiveStateIntensity = isP5StateActive ? 1.0 : 0.0; activeStateIntensity = p.lerp(activeStateIntensity, targetActiveStateIntensity, activeStateLerpFactor * timeDelta);
    pauseEnded = false; if (isP5StateActive && smoothedOverallLevel < silenceThreshold) { silenceFrames++; } else { if (silenceFrames >= framesForPause) { pauseEnded = true; pauseEffectTimer = pauseEffectDuration; pauseEffectIntensity = 1.0; inhaleAmount = -1.0; } silenceFrames = 0; isBreathing = false; } if (silenceFrames >= framesForBreathing) { isBreathing = true; breathingTime += breathingSpeed * timeDelta; }
    if (pauseEffectTimer > 0) pauseEffectTimer--; pauseEffectIntensity = p.lerp(pauseEffectIntensity, 0, pauseEffectDecay); if (pauseEnded || inhaleAmount !== 0) { inhaleAmount = p.lerp(inhaleAmount, 1.0, inhaleSpeed);} if (Math.abs(inhaleAmount - 1.0) < 0.01) inhaleAmount = 0;
    let currentSlowSpeedMultiplier = 1.0; let currentFastSpeedMultiplier = 1.0; if (isP5StateActive && smoothedOverallLevel > audioThreshold) { const mapStartLevel = audioThreshold + 0.02; const mapEndLevel = 0.85; currentSlowSpeedMultiplier = p.map(smoothedOverallLevel, mapStartLevel, mapEndLevel, 1.0, maxSlowSpeedMultiplier, true); currentFastSpeedMultiplier = p.map(smoothedOverallLevel, mapStartLevel, mapEndLevel, 1.0, maxFastSpeedMultiplier, true); }
    let targetFocusFactor = 0.0, targetMelodyFactor = 0.0, targetEmphasisFactor = 0.0; if (isP5StateActive && smoothedOverallLevel > audioThreshold) { targetFocusFactor = p.map(frequencySpread, 0.3, 0.7, 0, 1, true) * p.map(pitchChangeRate, 0.05, 0.005, 0, 1, true); targetMelodyFactor = p.map(pitchChangeRate, 0.01, 0.1, 0, 1, true); targetEmphasisFactor = p.map(smoothedOverallLevel, 0.5, 0.9, 0, 1, true); if (isAhaMoment) targetEmphasisFactor = 1.0; } focusFactor = p.lerp(focusFactor, targetFocusFactor, focusFactorLerp); melodyFactor = p.lerp(melodyFactor, targetMelodyFactor, melodyFactorLerp); emphasisFactor = p.lerp(emphasisFactor, targetEmphasisFactor, emphasisFactorLerp);
    let rotationSpeedModifier = p.lerp(1.0, 0.8, focusFactor) * p.lerp(1.0, 1.2, melodyFactor); let finalSlowMultiplier = currentSlowSpeedMultiplier * p.lerp(1.0, 1.1, emphasisFactor); let finalFastMultiplier = currentFastSpeedMultiplier * p.lerp(1.0, 1.1, emphasisFactor); let finalOffsetMultiplier = currentFastSpeedMultiplier * rotationSpeedModifier * p.lerp(1.0, 1.1, emphasisFactor);
    let wavinessSpeedBoost = p.map(pitchChangeRate, 0.01, 0.1, 1.0, 2.5, true);
    passiveNoiseTime      += basePassiveNoiseSpeed      * (isP5StateActive ? finalSlowMultiplier : 1.0) * timeDelta;
    activeShapeNoiseTime    += baseActiveShapeNoiseSpeed    * finalFastMultiplier * timeDelta;
    activeTextureNoiseTime  += baseActiveTextureNoiseSpeed  * finalFastMultiplier * timeDelta;
    activeWavinessNoiseTime += baseActiveWavinessNoiseSpeed * finalSlowMultiplier * wavinessSpeedBoost * timeDelta;
    internalTextureTime += internalTextureSpeed * timeDelta;
    activeNoiseAngularOffset += baseActiveNoiseOffsetSpeed * finalOffsetMultiplier * timeDelta; activeNoiseAngularOffset %= p.TWO_PI;
    let targetMultiplier = 1.0; let midTrebleCombined = smoothedMidLevel + smoothedTrebleLevel; if (isP5StateActive && midTrebleCombined > audioThreshold) { targetMultiplier = p.map(midTrebleCombined * p.lerp(1.0, 1.2, emphasisFactor), audioThreshold + 0.02, 0.9, 1.0, maxPeakExtensionFactor, true); } activePeakMultiplier = p.lerp(activePeakMultiplier, targetMultiplier, activeMultiplierLerpFactor * timeDelta);
    let targetWavinessInfluence = 0; if(isP5StateActive && smoothedOverallLevel > audioThreshold){ targetWavinessInfluence = p.map(melodyFactor, 0.1, 0.9, 0.0, maxWavinessInfluence, true); } currentWavinessInfluence = p.lerp(currentWavinessInfluence, targetWavinessInfluence, wavinessInfluenceLerpFactor);
    let targetWavinessScale = baseWavinessNoiseScale; if(isP5StateActive && smoothedOverallLevel > audioThreshold){ targetWavinessScale = p.map(pitchProxy, 0, 1, baseWavinessNoiseScale * (1 + wavinessScalePitchFactor/2), baseWavinessNoiseScale * (1 - wavinessScalePitchFactor/2), true); targetWavinessScale = p.max(1.0, targetWavinessScale); } currentWavinessNoiseScale = p.lerp(currentWavinessNoiseScale, targetWavinessScale, wavinessScaleLerpFactor);
    let targetTextureIntensity = baseTextureIntensity; if(isP5StateActive && smoothedOverallLevel > audioThreshold){ targetTextureIntensity = p.map(frequencySpread, 0.1, 0.6, baseTextureIntensity, maxTextureIntensity, true) * p.lerp(1.0, 0.6, focusFactor); } currentActiveTextureIntensity = p.lerp(currentActiveTextureIntensity, targetTextureIntensity, textureIntensityLerpFactor);
    let targetShapeScale = baseActiveShapeNoiseScale; if(isP5StateActive && smoothedOverallLevel > audioThreshold) { let scaleModifier = p.map(frequencySpread, 0.1, 0.6, 1.0 + shapeScaleSpreadFactor, 1.0 - shapeScaleSpreadFactor, true); targetShapeScale = baseActiveShapeNoiseScale * scaleModifier; targetShapeScale = p.max(0.5, targetShapeScale); } currentActiveShapeNoiseScale = p.lerp(currentActiveShapeNoiseScale, targetShapeScale, shapeScaleLerpFactor);
    let targetPassiveDeformation = basePassiveDeformationAmount; if(isP5StateActive && sustainedMidLevel > audioThreshold * 1.2) { let boost = p.map(sustainedMidLevel, audioThreshold * 1.2, 0.6, 0, maxPassiveDeformationBoost, true); targetPassiveDeformation = basePassiveDeformationAmount + boost; } currentPassiveDeformationAmount = p.lerp(currentPassiveDeformationAmount, targetPassiveDeformation, passiveDeformationLerpFactor);
    let targetEdgeSharpness = 1.0; if(isP5StateActive && smoothedOverallLevel > audioThreshold){ let spreadSharpnessValue = p.map(frequencySpread, 0.1, 0.7, 1.0, 0.3, true); targetEdgeSharpness = p.lerp(spreadSharpnessValue, 1.0, focusFactor * 0.7); } edgeSharpness = p.lerp(edgeSharpness, targetEdgeSharpness, edgeSharpnessLerpFactor); // Use corrected logic
    let targetInternalAlpha = 0; const internalTextureThreshold = audioThreshold + 0.05; if(isP5StateActive && smoothedOverallLevel > internalTextureThreshold){ targetInternalAlpha = p.map(smoothedOverallLevel, internalTextureThreshold, 0.7, 0, maxInternalTextureAlpha, true) * p.lerp(0.5, 1.5, focusFactor); } internalTextureAlpha = p.lerp(internalTextureAlpha, targetInternalAlpha, internalAlphaLerpFactor);
    if (ahaTimer > 0) { ahaTimer--; if (ahaTimer <= 0) isAhaMoment = false; } flashIntensity = p.lerp(flashIntensity, 0, flashDecay);
  };

  // --- Update Color ---
  const updateColor = () => { targetHue = baseHue; if (isP5StateActive && smoothedOverallLevel > audioThreshold) { let spreadShift = p.map(frequencySpread, 0.1, 0.6, -hueShiftRange/3, hueShiftRange/3, true); let pitchShift = p.map(pitchProxy, 0, 1, -hueShiftRange/2, hueShiftRange/2, true); targetHue = (baseHue + spreadShift + pitchShift + 360) % 360; } let hueDiff = targetHue - currentHue; if (Math.abs(hueDiff) > 180) { if (hueDiff > 0) currentHue += 360; else currentHue -= 360; } currentHue = p.lerp(currentHue, targetHue, hueLerpFactor); currentHue = (currentHue + 360) % 360; saturationBoost = 0; brightnessBoost = 0; if (isP5StateActive && smoothedOverallLevel > audioThreshold) { const mapStartLevel = audioThreshold + 0.02; saturationBoost = p.map(smoothedOverallLevel, mapStartLevel, 0.9, 0, maxSaturationBoost, true); brightnessBoost = p.map(smoothedOverallLevel, mapStartLevel, 0.9, 0, maxBrightnessBoost, true); } let currentSaturationValue = p.constrain(baseSaturation + saturationBoost, 60, 95); let currentBrightnessValue = p.constrain(baseBrightness + brightnessBoost, 92, 100); let flashColor = p.color(50, 10, 100); let baseCenter = p.color(currentHue, currentSaturationValue * 0.9, currentBrightnessValue * 0.98, 100); let baseEdge = p.color(currentHue, currentSaturationValue, currentBrightnessValue, 95); currentCenterColor = p.lerpColor(baseCenter, flashColor, flashIntensity); currentEdgeColor = p.lerpColor(baseEdge, flashColor, flashIntensity); };

  // --- Blob Shape Calculation ---
  const calculateBlobShape = () => { let currentBaseRadius = baseRadius; let coreMod = 0; if(isBreathing){ coreMod += p.sin(breathingTime * p.TWO_PI) * breathingAmount; } if(inhaleAmount !== 0){ coreMod += p.sin(inhaleAmount * p.PI) * maxInhaleFactor * -1; } currentBaseRadius *= (1 + coreMod); for (let i = 0; i < numVertices; i++) { let angle = p.map(i, 0, numVertices, 0, p.TWO_PI); let cosAnglePassive = p.cos(angle); let sinAnglePassive = p.sin(angle); let passiveNoiseX = p.map(cosAnglePassive, -1, 1, 0, passiveNoisePosScale); let passiveNoiseY = p.map(sinAnglePassive, -1, 1, 0, passiveNoisePosScale); let passiveNoiseVal = p.noise(passiveNoiseX, passiveNoiseY, passiveNoiseTime); let passiveOffset = p.map(passiveNoiseVal, 0, 1, -currentPassiveDeformationAmount, currentPassiveDeformationAmount) * currentBaseRadius; let coreRadius = currentBaseRadius + passiveOffset; let peakExtensionOffset = 0; if (activeStateIntensity > 0.01 && isP5StateActive) { let activeAngle = (angle + activeNoiseAngularOffset) % p.TWO_PI; let cosAngleActive = p.cos(activeAngle); let sinAngleActive = p.sin(activeAngle); let shapeNoiseX = p.map(cosAngleActive, -1, 1, 0, currentActiveShapeNoiseScale); let shapeNoiseY = p.map(sinAngleActive, -1, 1, 0, currentActiveShapeNoiseScale); let shapeNoiseVal = p.noise(shapeNoiseX, shapeNoiseY, activeShapeNoiseTime); let textureNoiseX = p.map(cosAngleActive, -1, 1, 0, activeTextureNoiseScale); let textureNoiseY = p.map(sinAngleActive, -1, 1, 0, activeTextureNoiseScale); let textureNoiseVal = p.noise(textureNoiseX, textureNoiseY, activeTextureNoiseTime); let textureOffset = p.map(textureNoiseVal, 0, 1, -currentActiveTextureIntensity, currentActiveTextureIntensity); let wavinessNoiseX = p.map(cosAngleActive, -1, 1, 0, currentWavinessNoiseScale); let wavinessNoiseY = p.map(sinAngleActive, -1, 1, 0, currentWavinessNoiseScale); let wavinessNoiseVal = p.noise(wavinessNoiseX, wavinessNoiseY, activeWavinessNoiseTime); let wavinessOffset = p.map(wavinessNoiseVal, 0, 1, -1.0, 1.0) * currentWavinessInfluence; let combinedActiveNoiseShape = p.map(shapeNoiseVal, 0, 1, 0, 1) + textureOffset + wavinessOffset; let peakMagnitude = baseRadius * p.max(0, combinedActiveNoiseShape) * p.max(0, activePeakMultiplier - 1.0); peakExtensionOffset = peakMagnitude * activeStateIntensity; } let totalRadius = coreRadius + peakExtensionOffset; const minRadiusClamp = baseRadius * 0.2 * (1 - maxInhaleFactor); const maxCoreDeformation = baseRadius * (1 + basePassiveDeformationAmount + maxPassiveDeformationBoost + breathingAmount + maxInhaleFactor); const maxPeak = baseRadius * maxPeakExtensionFactor; const maxRadiusClamp = maxCoreDeformation + maxPeak * 1.2; totalRadius = p.constrain(totalRadius, minRadiusClamp, maxRadiusClamp); let x = totalRadius * p.cos(angle); let y = totalRadius * p.sin(angle); vertices[i].set(x, y); } };

  // --- Internal Texture Rendering ---
  const drawInternalTexture = () => { if (internalTextureAlpha <= 1) return; p.push(); p.noFill(); const textureColor = p.color(currentHue, baseSaturation * 0.5, baseBrightness * 1.1, internalTextureAlpha); p.stroke(textureColor); p.strokeWeight(0.75); const steps = 10; const maxOffset = baseRadius * 0.15; for (let step = 0; step < steps; step++) { let ratio = p.map(step, 0, steps, 0.2, 0.8); p.beginShape(); for (let i = 0; i < numVertices; i++) { let angle = p.map(i, 0, numVertices, 0, p.TWO_PI); let cosA = p.cos(angle); let sinA = p.sin(angle); let noiseVal1 = p.noise(cosA * internalTextureScale + 10, sinA * internalTextureScale + 20, internalTextureTime + step * 0.1); let noiseVal2 = p.noise(cosA * internalTextureComplexityScale + 30, sinA * internalTextureComplexityScale + 40, internalTextureTime * 0.5 + step * 0.05); let offset = p.map(noiseVal1 + noiseVal2, 0, 2, -maxOffset, maxOffset); let r = baseRadius * ratio + offset; r = p.max(baseRadius * 0.1, r); p.vertex(r * cosA, r * sinA); } p.endShape(p.CLOSE); } p.pop(); };

  // --- Blob Rendering ---
  const drawBlob = () => { const baseLayers = 8; const maxLayersBoost = 10; const baseAlphaStep = 2; const maxAlphaStepBoost = 6; let layers = p.floor(p.lerp(baseLayers, baseLayers + maxLayersBoost, edgeSharpness)); let alphaStep = p.lerp(baseAlphaStep, baseAlphaStep + maxAlphaStepBoost, edgeSharpness); let radiusStepRatio = p.lerp(0.04, 0.02, edgeSharpness); layers = p.max(3, layers); for (let layer = 0; layer < layers; layer++) { let layerRadiusRatio = 1.0 - (layer * radiusStepRatio); let layerAlpha = p.alpha(currentEdgeColor) - layer * alphaStep; let layerColor = p.lerpColor(currentCenterColor, currentEdgeColor, p.map(layer, 0, layers - 1, 0, 1)); layerColor.setAlpha(p.max(0, layerAlpha)); p.noStroke(); p.fill(layerColor); p.beginShape(); p.curveVertex(vertices[numVertices - 1].x * layerRadiusRatio, vertices[numVertices - 1].y * layerRadiusRatio); for (let i = 0; i < numVertices; i++) { p.curveVertex(vertices[i].x * layerRadiusRatio, vertices[i].y * layerRadiusRatio); } p.curveVertex(vertices[0].x * layerRadiusRatio, vertices[0].y * layerRadiusRatio); p.curveVertex(vertices[1].x * layerRadiusRatio, vertices[1].y * layerRadiusRatio); p.endShape(p.CLOSE); } };

  // --- Pause Effect Rendering ---
  const drawPauseEffect = () => { if(pauseEffectIntensity <= 0.01) return; let rippleRadius = baseRadius * (1 + currentPassiveDeformationAmount + breathingAmount) * 1.1 * (1.0 - pauseEffectIntensity); let rippleAlpha = pauseEffectIntensity * 50; let rippleWeight = p.lerp(0.5, 3, pauseEffectIntensity); let currentSaturationValue = p.constrain(baseSaturation + saturationBoost, 60, 95); let currentBrightnessValue = p.constrain(baseBrightness + brightnessBoost, 92, 100); p.push(); p.noFill(); p.strokeWeight(rippleWeight); let rippleColor = p.color(currentHue, currentSaturationValue * 0.8, currentBrightnessValue, rippleAlpha); p.stroke(rippleColor); p.ellipse(0, 0, rippleRadius * 2, rippleRadius * 2); p.pop(); }

  // --- External Control & Cleanup ---
  p.activate = async () => { console.log("p5: Received activation request."); silenceFrames = 0; isBreathing = false; pauseEnded = false; pauseEffectTimer = 0; pauseEffectIntensity = 0; inhaleAmount = 0; const success = await setupAudio(); if (success) { isP5StateActive = true; } else { isP5StateActive = false; } return success; };
  p.deactivate = () => { console.log("p5: Received deactivation request."); isP5StateActive = false; isBreathing = false; pauseEnded = false; pauseEffectTimer = 0; pauseEffectIntensity = 0; inhaleAmount = 0; stopAudioProcessing(); };
  p.cleanup = () => { console.log("p5: Cleaning up sketch and audio."); stopAudioProcessing(); if (audioContext && audioContext.state !=='closed') { audioContext.close().then(() => console.log("AudioContext closed.")).catch(e => console.error("Error closing context on cleanup:", e)); audioContext = null; } p.remove(); console.log("p5 cleanup complete."); };
  p.windowResized = () => { const container = document.getElementById('canvas-container'); if (!container) return; p.resizeCanvas(container.offsetWidth, container.offsetHeight); baseRadius = p.min(p.width, p.height) / 5.0; console.log(`Resized, new baseRadius: ${baseRadius}`); };
};

// --- React Component Definition ---
const AudioReactivePaintBlob = () => {
  const canvasContainerRef = useRef(null); const p5InstanceRef = useRef(null);
  const [isUserActiveState, setIsUserActiveState] = useState(false);
  const [errorMessage, setErrorMessage] = useState('');
  useEffect(() => { let p5instance; import('p5').then(p5 => { if (canvasContainerRef.current && !p5InstanceRef.current) { p5instance = new p5.default(sketch, canvasContainerRef.current); p5InstanceRef.current = p5instance; console.log("React: p5 instance created."); } }).catch(error => { console.error("Failed to load p5.js:", error); setErrorMessage("Failed to load visualization component."); }); return () => { if (p5InstanceRef.current) { console.log("React: Cleaning up p5 instance."); p5InstanceRef.current.cleanup(); p5InstanceRef.current = null; } }; }, []);
  const handleCanvasClick = useCallback(async () => { if (!p5InstanceRef.current) return; setErrorMessage(''); if (isUserActiveState) { console.log("React: User clicked to Deactivate."); p5InstanceRef.current.deactivate(); setIsUserActiveState(false); } else { console.log("React: User clicked to Activate."); try { const success = await p5InstanceRef.current.activate(); if (success) { console.log("React: Activation successful."); setIsUserActiveState(true); } else { console.log("React: Activation failed (likely permissions)."); setErrorMessage("Could not enable microphone. Please check browser permissions."); setIsUserActiveState(false); } } catch (error) { console.error("React: Error during activation:", error); setErrorMessage("An unexpected error occurred while activating the microphone."); setIsUserActiveState(false); } } }, [isUserActiveState]);
  return ( <ThemeProvider theme={theme}> <CssBaseline /> <Head> <title>LLM Sound Visualizer</title> <meta name="description" content="Emotionally expressive audio visualizer blob." /> </Head> <Box sx={{ display: 'flex', alignItems: 'center', justifyContent: 'center', minHeight: '100vh', bgcolor: 'background.default', p: 2, }}> <Paper id="canvas-container" ref={canvasContainerRef} elevation={0} onClick={handleCanvasClick} sx={{ width: 'clamp(300px, 90vw, 800px)', height: 'clamp(300px, 70vh, 600px)', display: 'flex', alignItems: 'center', justifyContent: 'center', cursor: 'pointer', position: 'relative' }}> {!p5InstanceRef.current && <span style={{color: grey[500]}}>Loading Visualizer...</span>} {errorMessage && ( <Box sx={{ position: 'absolute', bottom: 16, left: 16, right: 16, color: 'error.main', textAlign: 'center', backgroundColor: 'rgba(255, 235, 238, 0.9)', p: 1, borderRadius: 1, fontSize:'0.875rem', zIndex: 10 }}> {errorMessage} </Box> )} </Paper> </Box> </ThemeProvider> );
};
export default AudioReactivePaintBlob; // Export the component